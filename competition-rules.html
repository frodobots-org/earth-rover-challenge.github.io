<!DOCTYPE html><!--  This site was created in Webflow. https://webflow.com  --><!--  Last Published: Thu Jan 02 2025 06:31:39 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="67644773b9bde8d4ae7bad7c" data-wf-site="675adc559a34353550a9a029">
<head>
  <meta charset="utf-8">
  <title>Summit - Webflow Ecommerce website template</title>
  <meta content="Elevate Your Business and SaaS Endeavors with Summit - A Premium Webflow Template. Boasting CMS and E-commerce functionality, Summit empowers you with customizable layouts and seamless animations. With over 30 pages, craft your digital Summit, engage customers, and drive success in style." name="description">
  <meta content="Summit - Webflow Ecommerce website template" property="og:title">
  <meta content="Elevate Your Business and SaaS Endeavors with Summit - A Premium Webflow Template. Boasting CMS and E-commerce functionality, Summit empowers you with customizable layouts and seamless animations. With over 30 pages, craft your digital Summit, engage customers, and drive success in style." property="og:description">
  <meta content="https://cdn.prod.website-files.com/66eaf8c5b862e4b2fe2f57e7/66f2cdd61ef730f054b1e21b_opengraph%20summit.jpg" property="og:image">
  <meta content="Summit - Webflow Ecommerce website template" property="twitter:title">
  <meta content="Elevate Your Business and SaaS Endeavors with Summit - A Premium Webflow Template. Boasting CMS and E-commerce functionality, Summit empowers you with customizable layouts and seamless animations. With over 30 pages, craft your digital Summit, engage customers, and drive success in style." property="twitter:description">
  <meta content="https://cdn.prod.website-files.com/66eaf8c5b862e4b2fe2f57e7/66f2cdd61ef730f054b1e21b_opengraph%20summit.jpg" property="twitter:image">
  <meta property="og:type" content="website">
  <meta content="summary_large_image" name="twitter:card">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/earthrover-challenge.webflow.css" rel="stylesheet" type="text/css">
  <style>@media (min-width:992px) {html.w-mod-js:not(.w-mod-ix) [data-w-id="4adb4f2c-dff8-4cd7-63ae-deedd861bfb0"] {opacity:0;}html.w-mod-js:not(.w-mod-ix) [data-w-id="4763a34a-050a-eab0-924b-a74f059ee806"] {width:0vw;height:0vh;}}@media (max-width:991px) and (min-width:768px) {html.w-mod-js:not(.w-mod-ix) [data-w-id="4adb4f2c-dff8-4cd7-63ae-deedd861bfb0"] {opacity:0;}html.w-mod-js:not(.w-mod-ix) [data-w-id="4763a34a-050a-eab0-924b-a74f059ee806"] {width:0vw;height:0vh;}}@media (max-width:767px) and (min-width:480px) {html.w-mod-js:not(.w-mod-ix) [data-w-id="4adb4f2c-dff8-4cd7-63ae-deedd861bfb0"] {opacity:0;}html.w-mod-js:not(.w-mod-ix) [data-w-id="4763a34a-050a-eab0-924b-a74f059ee806"] {width:0vw;height:0vh;}}@media (max-width:479px) {html.w-mod-js:not(.w-mod-ix) [data-w-id="4adb4f2c-dff8-4cd7-63ae-deedd861bfb0"] {opacity:0;}html.w-mod-js:not(.w-mod-ix) [data-w-id="4763a34a-050a-eab0-924b-a74f059ee806"] {width:0vw;height:0vh;}}</style>
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.jpg" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.jpg" rel="apple-touch-icon">
</head>
<body>
  <div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" role="banner" class="navbar w-nav">
    <div class="padding-global">
      <div class="container large w-container">
        <div class="navbar-component">
          <a href="index.html" class="brand w-nav-brand"></a>
          <div class="right-navbar-content">
            <div class="nav-menu-wrap">
              <div class="menu-button w-nav-button">
                <div class="menu-icon w-icon-nav-menu"></div>
              </div>
            </div>
            <nav role="navigation" class="nav-menu w-nav-menu">
              <div data-delay="100" data-hover="true" data-w-id="47460df3-b7ad-bcd6-5bf9-476ef6b21079" class="nav-link w-dropdown">
                <article class="dropdown w-dropdown-toggle">
                  <div class="w-layout-blockcontainer container-6 w-container">
                    <a href="#overview" class="link-2">Overview</a>
                    <a href="#rules_and_format" class="link-2">Rules &amp; Format</a>
                    <a href="#dataset" class="link-2">Dataset</a>
                    <a href="#iros24" class="link-2">Past Iterations</a>
                    <a href="#testimonials" class="link-2">Testimonials</a>
                    <a href="#organizers" class="link-2">Organizers</a>
                  </div>
                </article>
                <nav class="dropdown-list w-dropdown-list"></nav>
              </div>
              <a href="https://docs.google.com/forms/d/e/1FAIpQLSfu6HbS1-ppK5FVARtwDwTYs7FcH5SRL4xbbbsXr2j4Um1KVQ/viewform" class="features-link navbar-margin w-inline-block">
                <div class="relative">
                  <div class="text-weight-medium">Sign Up</div>
                </div>
                <div class="button-mask"></div>
              </a>
            </nav>
          </div>
        </div>
      </div>
    </div>
    <div class="overlay-navbar"></div>
  </div>
  <section>
    <div class="hero-size align-bottom">
      <nav data-poster-url="videos/Iros-10-secs_1-poster-00001.jpg" data-video-urls="videos/Iros-10-secs_1-transcode.mp4,videos/Iros-10-secs_1-transcode.webm" data-autoplay="true" data-loop="true" data-wf-ignore="true" class="background-video w-background-video w-background-video-atom"><video id="ef97ec42-fc84-cb09-5462-274e1ff89b16-video" autoplay="" loop="" style="background-image:url(&quot;videos/Iros-10-secs_1-poster-00001.jpg&quot;)" muted="" playsinline="" data-wf-ignore="true" data-object-fit="cover">
          <source src="videos/Iros-10-secs_1-transcode.mp4" data-wf-ignore="true">
          <source src="videos/Iros-10-secs_1-transcode.webm" data-wf-ignore="true">
        </video><noscript>
          <style>
  [data-wf-bgvideo-fallback-img] {
    display: none;
  }
  @media (prefers-reduced-motion: reduce) {
    [data-wf-bgvideo-fallback-img] {
      position: absolute;
      z-index: -100;
      display: inline-block;
      height: 100%;
      width: 100%;
      object-fit: cover;
    }
  }</style><img data-wf-bgvideo-fallback-img="true" src="videos/Iros-10-secs_1-poster-00001.jpg" alt="">
        </noscript>
        <div aria-live="polite"><button type="button" data-w-bg-video-control="true" aria-controls="ef97ec42-fc84-cb09-5462-274e1ff89b16-video" class="w-backgroundvideo-backgroundvideoplaypausebutton w-background-video--control"><span><img src="https://uploads-ssl.webflow.com/6022af993a6b2191db3ed10c/628299f8aa233b83918e24fd_Pause.svg" loading="lazy" alt="Pause video"></span><span hidden=""><img loading="lazy" alt="Play video" src="https://uploads-ssl.webflow.com/6022af993a6b2191db3ed10c/628298b20ae0236682d4b87f_Play-24.svg"></span></button></div>
      </nav>
      <div class="relative">
        <div class="padding-global"></div>
      </div>
      <div class="hero-square-wrapper">
        <div data-w-id="4763a34a-050a-eab0-924b-a74f059ee806" class="hero-square">
          <div data-w-id="4adb4f2c-dff8-4cd7-63ae-deedd861bfb0" class="header text-color-white">
            <h1 class="heading-5">Rules &amp; Format</h1>
            <div class="max-width-45ch">
              <div class="w-layout-blockcontainer container w-container"></div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section>
    <div class="padding-global">
      <div class="w-layout-blockcontainer container w-container"></div>
    </div>
  </section>
  <section class="features-list">
    <section class="hero-without-image">
      <div class="container-3">
        <div class="hero-wrapper-two">
          <h1 class="heading-8">Competition Rules</h1>
          <p class="margin-bottom-24px">The Earth Rover Challenge is a distributed competition across remote environment scenarios spanning multiple cities (e.g., Abu Dhabi, Singapore, Taipei, Stockholm, etc.), where competition participants need to deploy their policies into realistic GPS goal-oriented navigation scenarios. This competition will test the robustness, generalization, and safety of navigation capabilities of robot foundation models. <br><br>*<em>The following is based on the 2024 iteration of the competition, and is subject to confirmation for future versions.</em><br>‍<br><strong>Navigation Missions<br>‍</strong>The goal of the competition is to remotely control small sidewalk robots in order to complete various navigation missions in outdoor urban environments across various cities in real time.Each mission consists of a series of checkpoints that the robot needs to navigate through. A checkpoint is specified using GPS coordinates.<br>Every mission is given certain award points: 1-10 based on the difficulty, e.g., whether crossing roads, crowded space, and is considered “mission complete” when the robot returns to the end point of the given mission after registering at various checkpoints.<br></p><img src="images/Screenshot-2024-12-20-at-1.46.19-AM.png" loading="lazy" sizes="(max-width: 479px) 84vw, 400px" srcset="images/Screenshot-2024-12-20-at-1.46.19-AM-p-500.png 500w, images/Screenshot-2024-12-20-at-1.46.19-AM-p-800.png 800w, images/Screenshot-2024-12-20-at-1.46.19-AM-p-1080.png 1080w, images/Screenshot-2024-12-20-at-1.46.19-AM-p-1600.png 1600w, images/Screenshot-2024-12-20-at-1.46.19-AM.png 1604w" alt="" class="image-10">
          <div class="text-block-3">Example of a navigation mission in Wuhan, consisting of a sequence of GPS-defined checkpoints.</div>
          <p class="paragraph-2"><br>The Earth Rover Challenge is a distributed competition across remote environment scenarios spanning multiple cities (e.g., Abu Dhabi, Singapore, Taipei, Stockholm, etc.), where competition participants need to deploy their policies into realistic GPS goal-oriented navigation scenarios. This competition will test the robustness, generalization, and safety of navigation capabilities of robot foundation models. <br><br>*<em>The following is based on the 2024 iteration of the competition, and is subject to confirmation for future versions.</em><br>‍<br><strong>Navigation Missions<br>‍</strong>The goal of the competition is to remotely control small sidewalk robots in order to complete various navigation missions in outdoor urban environments across various cities in real time.Each mission consists of a series of checkpoints that the robot needs to navigate through. A checkpoint is specified using GPS coordinates.<br>Every mission is given certain award points: 1-10 based on the difficulty, e.g., whether crossing roads, crowded space, and is considered “mission complete” when the robot returns to the end point of the given mission after registering at various checkpoints.<br><br><strong>Competition Format<br>‍</strong>The competition will proceed in a round robin fashion where AI teams and human gamers will take turns to complete known and unknown navigation missions in various test locations/cities.<br><br> Concretely, there will be 2 robots at each location, with either robots controlled by AI team&#x27;s model or a human gamer (it&#x27;s also possible for both robots to be controlled by 2 AI team&#x27;s models or 2 human gamers). Both robots will start at the same starting point, albeit with a few minutes difference in staggered starting time, while working towards completing the same navigation mission (with the same series of checkpoints). Each mission will have a difficulty score ranging from 1 to 10. <br><br>Example of a simple mission may include a short distance drive (eg. 100 meter) in a typically quiet park with wide sidewalk while a more difficult drive could involve a long drive (eg. 1 km) along crowded sidewalk while requiring crossing roads or even traveling directly on roads at times. It is also important to highlight that because this competition takes place in the wild, real world variability will naturally mean that the conditions of every drive may differ even for the same mission (eg. a typically quiet park getting crowded unexpectedly). <br><br>Successfully completing a given mission will earn the AI team or human gamer competition points that correspond to the difficulty score (ie. completing a level 1 mission will earn 1 point). Failure to complete a mission or needing any intervention by the &quot;robot walker assistant&quot; will mean the AI team or human gamer will not receive any point for that particular round/mission.<br>‍<br>At the end of the competition, the AI team or human gamer with the highest aggregate points will win the competition. If there is a tie (in points), we will refer to the particular round where the 2 opponents faced each other in the same mission and whoever completed that mission sooner will be considered the ultimate winner.<br><br><strong>Robot Platform<br>‍</strong>Each Earth Rover unit weighs less than 5 kg (11 lbs) and moves at a max speed of ~3 km/hr (~0.85 m/s). It is able to move forward/backwards, turn in-place and comes equipped with front/back cameras, 4G connection, GPS &amp; IMU. It has limited edge computing and is meant to be 100% remotely controlled by human drivers or AI navigation models hosted on a remote server (e.g., your in-house compute, or the cloud).<br>Every participating team will be given 2 Earth Rover units for testing locally as well as up to 20 hours test time per week (in the coming months leading to the actual competition at IROS) with robots deployed remotely around the world (along with human operators who will follow closely behind the robots to provide real-time operational support to the participating teams).<br><br><strong>Navigation Models Deployment<br>‍</strong>Competing teams shall host their own models in their own compute facilities while remotely accessing the assigned robots via a standard Remote Access SDK (<a href="https://github.com/frodobots-org/earth-rovers-sdk" target="_blank">GitHub Repo here</a>). <br><br>Effectively, AI team&#x27;s model will receive video stream from the front camera of the robot while it can also send through a control data stream to the robot. In addition, GPS location of the robot, as well as other specific info related to a given navigation mission (eg. GPS of the next checkpoint, neighborhood map) will also be provided.<br><br><strong>‍</strong></p>
          <div style="padding-top:75%" class="video-2 w-video w-embed"><iframe class="embedly-embed" src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.loom.com%2Fembed%2F4c2e16975c3e482eb364823528e79171&display_name=Loom&url=https%3A%2F%2Fwww.loom.com%2Fshare%2F4c2e16975c3e482eb364823528e79171%3Fsid%3D28dc6d2e-0b65-42ef-ae3b-cfda85148435&image=https%3A%2F%2Fcdn.loom.com%2Fsessions%2Fthumbnails%2F4c2e16975c3e482eb364823528e79171-00001.gif&type=text%2Fhtml&schema=loom" width="940" height="705" scrolling="no" allowfullscreen="" title="Earth Rovers Remote SDK v1.0"></iframe></div>
          <p><strong>Dataset<br>‍</strong>FrodoBots has also open-sourced a significant dataset of human tele-operated drives collected from 10+ cities (&gt;2k hours), which the teams can opt to adopt as part of their models training pipeline. There are 7 types of data that are associated with a typical Earth Rovers drive, as follows:<br><br>1. Control data: Gamer&#x27;s control inputs captured at a frequency of 10Hz (Ideal) as well as the RPM (revolutions per minute) readings for each of the 4 wheels on the robot.<br><br>2. GPS data: Latitude, longitude, and timestamp info collected during the robot drives at a frequency of 1Hz.<br><br>3. IMU (Inertial Measurement Unit) data: 9-DOF sensor data, including acceleration (captured at 100Hz), gyroscope (captured at 1Hz), and magnetometer info (captured at 1Hz), along with timestamp data.<br><br>4. Rear camera video: Video footage captured by the robot&#x27;s rear-facing camera at a typical frame rate of 20 FPS with a resolution of 540x360.<br><br>5. Front camera video: Video footage captured by the robot&#x27;s front-facing camera at a typical frame rate of 20 FPS with a resolution of 1024x576.<br><br>6. Microphone: Audio recordings captured by the robot&#x27;s microphone, with a sample rate of 16000Hz, channel 1.<br><br> 7. Speaker: Audio recordings of the robot&#x27;s speaker output (ie. gamer&#x27;s microphone), also with a sample rate of 16000Hz, channel More information about the currently released dataset can be found here: <a href="https://huggingface.co/datasets/frodobots/FrodoBots-2K" target="_blank">https://huggingface.co/datasets/frodobots/FrodoBots-2K<br>‍</a>
          </p>
          <p><strong>Models Testing Phase<br>‍</strong>In the months leading up to the actual competition, participants can test out their models on open-world sites with pre-defined navigation missions (“seen environments”). During the actual competition, participants will attempt to complete navigation missions in both seen and unseen environments across at least 4 open-world sites.<br><br>‍<strong>Observation space: </strong>The robot will have access to a front-facing camera view that will be updated at roughly 20 Hz, depending on the network connection. Depending on network conditions, the latency of the streaming data will be around 500 milliseconds.<br><br>‍<strong>Action space: </strong>The robot will be able to move forwards and backwards, or turn left and right. More details on these actions can be found in the documentation of the Remote Access SDK.<br><br>‍<strong>Success criteria: </strong>The robot is deemed to have successfully reached the next checkpoint if it comes within 15 meters of that point, allowing for the tolerance of noisy GPS data.<br><br>‍<strong>Operation Support: </strong>In the months leading up to the competition date, we will provide locations across multiple citis (e.g., parks, campuses, public sidewalks) for teams to test their model in the real world, remotely. Teams can expect up to 20 hours per week of testing time, and a human &quot;bot walker&quot; will be following their robots to provide real-time ops support. The actual challenge at the conference will be similar, except new locations that the teams have not seen will be added.<br><br>‍<strong>Human Performance Benchmark<br>‍</strong>During the competition, 5 human drivers (winners selected from humans-only tournaments held before The Earth Rover Challenge) will also attempt to complete the same missions alongside robots controlled by other participants’ models. The human drivers are subject to the same conditions of “seen” vs “unseen” environments. This will help to form the human performance benchmark.</p>
        </div>
      </div>
    </section>
    <div class="container-3"></div>
  </section>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=675adc559a34353550a9a029" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
</body>
</html>